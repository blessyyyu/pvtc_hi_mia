{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3336, 0.3336],\n",
      "        [0.3333, 0.3334],\n",
      "        [0.3331, 0.3330]], grad_fn=<TransposeBackward0>)\n",
      "tensor([[[-0.0389,  0.0748,  0.2427, -0.0142, -0.0434,  0.1776],\n",
      "         [-0.0644,  0.0985,  0.2304, -0.0214, -0.0396,  0.1564]],\n",
      "\n",
      "        [[ 0.0618,  0.0183,  0.2834, -0.0287, -0.0695,  0.2872],\n",
      "         [ 0.0153,  0.1182,  0.2851,  0.0334, -0.1488,  0.2090]],\n",
      "\n",
      "        [[ 0.1490,  0.0006,  0.2879, -0.0357, -0.0890,  0.3538],\n",
      "         [ 0.0657,  0.0694,  0.3803, -0.0044, -0.1232,  0.3366]]],\n",
      "       grad_fn=<StackBackward>)\n",
      "tensor([[[-0.0130,  0.0250,  0.0810, -0.0047, -0.0145,  0.0592],\n",
      "         [-0.0215,  0.0329,  0.0768, -0.0071, -0.0132,  0.0522]],\n",
      "\n",
      "        [[ 0.0206,  0.0061,  0.0945, -0.0096, -0.0231,  0.0957],\n",
      "         [ 0.0051,  0.0394,  0.0950,  0.0111, -0.0496,  0.0697]],\n",
      "\n",
      "        [[ 0.0496,  0.0002,  0.0959, -0.0119, -0.0297,  0.1178],\n",
      "         [ 0.0219,  0.0231,  0.1266, -0.0015, -0.0410,  0.1121]]],\n",
      "       grad_fn=<CatBackward>)\n",
      "tensor([[-0.1510, -0.0324, -0.2105, -0.1019],\n",
      "        [-0.1221, -0.0424, -0.2429, -0.1090]], grad_fn=<AddmmBackward>)\n",
      "torch.Size([2, 4])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class SimpleAttenGRU(nn.Module):\n",
    "    def __init__(self, classes):\n",
    "        super(SimpleAttenGRU, self).__init__()\n",
    "        self.feature_dim = 4\n",
    "        self.hidden_dim = 6\n",
    "        self.output_dim = classes\n",
    "        self.num_layers = 2\n",
    "        self.gru = nn.GRU(self.feature_dim, self.hidden_dim, self.num_layers, dropout=0.2)\n",
    "        self.fc = nn.Linear(self.hidden_dim, classes)\n",
    "        self.softmax = nn.Softmax(dim=1) \n",
    "        self.tanh = nn.Tanh()\n",
    "        # atten parameter\n",
    "        self.weight_proj = nn.Parameter(torch.Tensor(self.hidden_dim, 1))\n",
    "        self.weight_W = nn.Parameter(torch.Tensor(self.hidden_dim, self.hidden_dim))\n",
    "        self.bias = nn.Parameter(torch.Tensor(self.hidden_dim,1))\n",
    "        self.weight_proj.data.uniform_(-0.1, 0.1)\n",
    "        self.weight_W.data.data.uniform_(-0.1, 0.1)\n",
    "\n",
    "    def batch_soft_atten(self, seq, W, bias, v):\n",
    "        s = []\n",
    "        batch_size = seq.shape[1]\n",
    "        bias_dim = bias.size()\n",
    "        for i in range(seq.size(0)):\n",
    "            _s = torch.mm(seq[i], W)\n",
    "            _s_bias = _s + bias.expand(bias_dim[0], batch_size).transpose(0,1)\n",
    "            _s_bias = torch.tanh(_s_bias)\n",
    "            _s = torch.mm(_s_bias, v)\n",
    "            s.append(_s)\n",
    "        s = torch.cat(s, dim=1)\n",
    "        soft = self.softmax(s)\n",
    "        return soft\n",
    "    \n",
    "    def attention_mul(self, rnn_outputs, att_weights):\n",
    "        print(att_weights)\n",
    "        print(rnn_outputs)\n",
    "        attn_vectors = []\n",
    "        for i in range(rnn_outputs.size(0)):\n",
    "            h_i = rnn_outputs[i]\n",
    "            a_i = att_weights[i].unsqueeze(1).expand_as(h_i)\n",
    "            h_i = a_i * h_i\n",
    "            h_i = h_i.unsqueeze(0)\n",
    "            attn_vectors.append(h_i)\n",
    "        attn_vectors = torch.cat(attn_vectors, dim=0)\n",
    "        print(attn_vectors)\n",
    "        return torch.sum(attn_vectors, 0)\n",
    "\n",
    "    def soft_attention(self, ht):\n",
    "        atten_alpha = self.batch_soft_atten(ht, self.weight_W, self.bias, self.weight_proj)\n",
    "        atten_vects = self.attention_mul(ht, atten_alpha.transpose(0, 1))\n",
    "        return atten_vects\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.reshape(x.shape[0], x.shape[2], x.shape[3])\n",
    "        x = x.transpose(0, 1) # batch second\n",
    "        self.gru.flatten_parameters()\n",
    "        # self.hidden = self.init_hidden(x.shape[1])\n",
    "        x, ht = self.gru(x)\n",
    "        x = self.soft_attention(x)\n",
    "        x = self.fc(x)\n",
    "        return x, x\n",
    "\n",
    "def test():\n",
    "    data = torch.rand(2, 1, 3, 4)\n",
    "    net = SimpleAttenGRU(4)\n",
    "    result, _ = net(data)\n",
    "    print(result)\n",
    "    print(result.shape)\n",
    "    \n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9046, 0.9046, 0.9046, 0.9046, 0.9046, 0.9046, 0.9046, 0.9046, 0.9046,\n",
       "         0.9046],\n",
       "        [0.2859, 0.2859, 0.2859, 0.2859, 0.2859, 0.2859, 0.2859, 0.2859, 0.2859,\n",
       "         0.2859],\n",
       "        [0.3921, 0.3921, 0.3921, 0.3921, 0.3921, 0.3921, 0.3921, 0.3921, 0.3921,\n",
       "         0.3921]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_i = torch.rand((3, 10))\n",
    "a = torch.rand(3)\n",
    "a.unsqueeze(1).expand_as(h_i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73779204"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.1450 * 0.8505 + 0.6774 * 0.9071"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 10, 8])\n",
      "torch.Size([10, 3, 16])\n"
     ]
    }
   ],
   "source": [
    "lstm = nn.LSTM(4, 8, 3, bidirectional=True, dropout=0.2, batch_first=True)\n",
    "input = torch.randn(10, 3, 4)\n",
    "output, (hn, cn) = lstm(input)\n",
    "print(hn.shape)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://api.touhou.center/link/pgc82nOjmnCVowf1?mu=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.6043212e-04 -3.0881882e-04 -1.3164947e-04  3.7886473e-04\n",
      " -1.0629969e-03 -1.2927054e-04 -8.8009183e-06  2.1792934e-04\n",
      "  2.6774674e-04  4.2166191e-04] 16000\n",
      "[-0.00201416 -0.00198364 -0.00177002 -0.00140381 -0.00097656 -0.00106812\n",
      " -0.00146484 -0.00140381 -0.00119019 -0.00094604] 48000\n",
      "[ 1.22070312e-04 -2.74658203e-04 -1.83105469e-04  3.96728516e-04\n",
      " -1.06811523e-03 -9.15527344e-05 -6.10351562e-05  2.74658203e-04\n",
      "  2.44140625e-04  4.57763672e-04] 16000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.00608997159596214"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import librosa\n",
    "import soundfile as sf\n",
    "y1, s1 = librosa.load('/NASdata/AudioData/farfieldsvc20/data1_0/S0377/377MIC/S0377_377MIC_Tr4_0013_normal.wav', sr=16000)\n",
    "y2, s2 = sf.read('/NASdata/AudioData/farfieldsvc20/data1_0/S0377/377MIC/S0377_377MIC_Tr4_0013_normal.wav')\n",
    "y3, s3 = sf.read('/mingback/wuhw/new_code/hotword_mia/set1_full/temp.wav')\n",
    "print(y1[100:110], s1)\n",
    "print(y2[100:110], s2)\n",
    "print(y3[100:110], s3)\n",
    "\n",
    "sum(y1 - y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2, -2])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array([1,2])-np.array([3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "         [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "         [0.9408, 0.1332, 0.9346, 0.5936]],\n",
      "\n",
      "        [[0.8694, 0.5677, 0.7411, 0.4294],\n",
      "         [0.8854, 0.5739, 0.2666, 0.6274],\n",
      "         [0.2696, 0.4414, 0.2969, 0.8317]]])\n",
      "tensor([[[0.7849],\n",
      "         [0.5104],\n",
      "         [0.6505]],\n",
      "\n",
      "        [[0.6519],\n",
      "         [0.5883],\n",
      "         [0.4599]]])\n",
      "tensor([[0.7378, 0.5497, 0.5247, 0.7822],\n",
      "        [0.6748, 0.5277, 0.4349, 0.6295]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "seed=42\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "\n",
    "m = nn.AdaptiveAvgPool1d(1)\n",
    "\n",
    "a = torch.rand(2,3,4)\n",
    "print(a)\n",
    "print(m(a))\n",
    "print(a.mean(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4.93955074 -6.52471115 -6.1474677  -6.47977597 -5.63165226 -4.31584805\n",
      " -4.35876351 -4.14273914 -3.50394311 -3.05466163 -2.48976352 -2.0258619\n",
      " -1.52955206 -1.57884562 -1.5049025  -0.84848871 -0.99518019  0.16581019\n",
      "  0.28213012  0.56030019  0.97564214  0.84956472  1.15563518  1.50326165\n",
      "  1.53498143  1.64203316]\n",
      "[-4.81124017 -6.09956452 -6.34379177 -5.64317338 -5.30244273 -4.3060827\n",
      " -3.89037145 -3.30734558 -2.89382744 -2.56346426 -2.33915007 -2.14876234\n",
      " -1.581807   -1.45751149 -1.23497027 -0.77835665 -0.68489126  0.00663928\n",
      "  0.47352691  0.56563818  0.51418323  0.8035424   1.53860474  1.7074354\n",
      "  1.46857081  1.86733401]\n"
     ]
    }
   ],
   "source": [
    "import python_speech_features as psf\n",
    "import numpy as np\n",
    "\n",
    "seed=42\n",
    "np.random.seed(seed)\n",
    "\n",
    "a = np.random.rand(1024 + 1024)\n",
    "feat = psf.logfbank(a, 16000)\n",
    "\n",
    "print(feat[4], )\n",
    "print(feat[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 26)\n",
      "[[-4.98175403e+00 -6.06505083e+00 -5.67174738e+00 -6.11272937e+00\n",
      "  -5.16250513e+00 -4.04992347e+00 -4.44226366e+00 -4.14106094e+00\n",
      "  -3.38071139e+00 -3.01323623e+00 -2.56080188e+00 -2.07839679e+00\n",
      "  -1.51707965e+00 -1.62020009e+00 -1.55650648e+00 -8.39185077e-01\n",
      "  -9.57506717e-01  1.72936835e-01  2.70355398e-01  5.70528816e-01\n",
      "   9.74542858e-01  8.39284674e-01  1.14782291e+00  1.50756152e+00\n",
      "   1.53530176e+00  1.64017815e+00]\n",
      " [-4.81124017e+00 -6.09956452e+00 -6.34379177e+00 -5.64317338e+00\n",
      "  -5.30244273e+00 -4.30608270e+00 -3.89037145e+00 -3.30734558e+00\n",
      "  -2.89382744e+00 -2.56346426e+00 -2.33915007e+00 -2.14876234e+00\n",
      "  -1.58180700e+00 -1.45751149e+00 -1.23497027e+00 -7.78356651e-01\n",
      "  -6.84891256e-01  6.63927728e-03  4.73526907e-01  5.65638175e-01\n",
      "   5.14183235e-01  8.03542396e-01  1.53860474e+00  1.70743540e+00\n",
      "   1.46857081e+00  1.86733401e+00]\n",
      " [-4.91368139e+00 -6.08296856e+00 -5.93096689e+00 -5.69963954e+00\n",
      "  -5.59985820e+00 -3.83513195e+00 -4.04830164e+00 -3.50525823e+00\n",
      "  -2.99721089e+00 -2.62634416e+00 -2.53859882e+00 -1.76637815e+00\n",
      "  -1.50389201e+00 -1.61345043e+00 -1.23029807e+00 -4.32657442e-01\n",
      "  -6.33290410e-01 -5.15910847e-01  3.77859575e-01  4.40068416e-01\n",
      "  -4.83303226e-02  9.21033550e-01  1.41388351e+00  1.76929523e+00\n",
      "   1.56372160e+00  2.07180004e+00]\n",
      " [-5.34701116e+00 -5.40990254e+00 -5.37571841e+00 -5.87307300e+00\n",
      "  -6.23250849e+00 -4.33463684e+00 -3.49364160e+00 -3.73895600e+00\n",
      "  -3.67440017e+00 -2.71302987e+00 -2.47642321e+00 -1.30085931e+00\n",
      "  -1.39131214e+00 -1.61274799e+00 -1.32777930e+00 -7.50228014e-01\n",
      "  -6.10302234e-01 -1.69771405e-01  1.34875673e-01  5.21141237e-01\n",
      "   4.33177083e-01  8.63358418e-01  1.35807736e+00  1.55120202e+00\n",
      "   1.61455773e+00  2.09427823e+00]\n",
      " [-5.06265321e+00 -6.07053091e+00 -6.49255391e+00 -5.79037213e+00\n",
      "  -5.31255052e+00 -4.93880305e+00 -3.51935150e+00 -3.71332839e+00\n",
      "  -3.91543495e+00 -4.68711025e+00 -3.22186830e+00 -1.48823550e+00\n",
      "  -1.40739280e+00 -1.39622180e+00 -1.05553547e+00 -7.24665705e-01\n",
      "  -5.46307762e-01 -1.83250527e-01 -1.16189628e-01  5.04833233e-01\n",
      "   6.25920053e-01  7.34700159e-01  1.17554681e+00  1.30276499e+00\n",
      "   1.68823408e+00  2.14701340e+00]\n",
      " [-5.11555252e+00 -6.86519259e+00 -6.06227788e+00 -4.94242366e+00\n",
      "  -5.23918953e+00 -4.93400473e+00 -3.76033334e+00 -4.01837694e+00\n",
      "  -3.87402534e+00 -2.51182356e+00 -2.94884098e+00 -2.06390947e+00\n",
      "  -1.60278482e+00 -1.21740349e+00 -9.75567386e-01 -5.69187601e-01\n",
      "  -4.21123582e-01 -7.70945143e-02  2.51240445e-01  5.09801644e-01\n",
      "   4.87006187e-01  5.33028509e-01  1.21702713e+00  1.16196021e+00\n",
      "   1.75462126e+00  2.04468247e+00]\n",
      " [-4.90006677e+00 -5.95130960e+00 -6.13588655e+00 -5.18378676e+00\n",
      "  -5.48932355e+00 -5.18439565e+00 -3.60162169e+00 -3.25610662e+00\n",
      "  -3.34521008e+00 -2.43648284e+00 -2.69020726e+00 -2.21298658e+00\n",
      "  -1.41715234e+00 -9.89633915e-01 -9.08301687e-01 -7.90826943e-01\n",
      "  -2.82749678e-01  1.96862834e-01  2.65903549e-01  3.93652386e-01\n",
      "   6.54113850e-01  9.79106982e-01  1.16299452e+00  9.77539369e-01\n",
      "   1.45427173e+00  1.88472443e+00]\n",
      " [-4.99213115e+00 -6.68713770e+00 -6.82427804e+00 -6.51144934e+00\n",
      "  -5.63548095e+00 -5.16356844e+00 -4.36877098e+00 -3.83747282e+00\n",
      "  -4.17147523e+00 -3.32273987e+00 -3.09431235e+00 -2.42864016e+00\n",
      "  -1.74610613e+00 -1.77566196e+00 -1.61626191e+00 -8.95155998e-01\n",
      "  -4.67352190e-01  1.19733224e-01 -1.25995962e-01  1.02262199e-01\n",
      "   5.10995744e-01  7.79686400e-01  2.22768393e-01  7.91098309e-01\n",
      "   1.50325488e+00  1.38793136e+00]]\n"
     ]
    }
   ],
   "source": [
    "b = a[1024 - 384:2048]\n",
    "feat = psf.logfbank(b, 16000)\n",
    "\n",
    "print(feat.shape)\n",
    "print(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-4.77910715 -5.46879802 -5.34576031 -5.26791882 -4.54709796 -4.96512749\n",
      "  -4.17591987 -4.204888   -3.39106558 -2.93785614 -3.05222423 -2.46972068\n",
      "  -1.92612542 -1.76183856 -1.49251159 -0.86357519 -0.47438309 -0.28621509\n",
      "   0.14387222  0.8014804   0.93206971  1.39270625  1.18107353  1.42804694\n",
      "   1.40156358  1.89118013]\n",
      " [-4.93143555 -6.26429507 -5.17895452 -5.00482973 -4.67812227 -5.05614044\n",
      "  -4.54020211 -4.49377483 -3.20058672 -2.51452663 -2.41508459 -1.98553913\n",
      "  -1.62526181 -1.91354478 -1.47264457 -0.97997278 -0.71918304 -0.21528469\n",
      "  -0.03641704  0.79233259  1.01852533  1.17398467  1.06814919  1.0495659\n",
      "   1.32057146  1.83585782]\n",
      " [-4.83790508 -6.15481286 -5.35652131 -5.40937509 -4.72557808 -4.22157644\n",
      "  -4.24984886 -4.79734349 -4.00832909 -2.80883781 -2.4141242  -2.23253035\n",
      "  -1.81837507 -2.23352592 -1.60491676 -0.38910135 -0.48411094 -0.3006112\n",
      "   0.30020467  0.64288631  0.95623187  1.23031406  1.256851    1.06795645\n",
      "   1.29900423  1.54045157]]\n",
      "[[-4.75516887 -5.98586146 -5.19946775 -5.2264838  -4.81164387 -4.111654\n",
      "  -4.19047635 -4.6946728  -4.10210643 -2.78114077 -2.37723854 -2.26062785\n",
      "  -1.84061993 -2.19528071 -1.64399939 -0.40639467 -0.4815788  -0.29427227\n",
      "   0.3101396   0.63539513  0.96062973  1.23013309  1.25474397  1.09722237\n",
      "   1.30913422  1.53608857]]\n"
     ]
    }
   ],
   "source": [
    "c = np.random.rand(720)\n",
    "print(psf.logfbank(c, 16000))\n",
    "print(psf.logfbank(c[320:], 16000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "480"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1024 16000 5\n",
    "# 2048 16000 12\n",
    "import math\n",
    "math.ceil(((16000 / 16000) - 0.015) / 0.01)\n",
    "import numpy as np\n",
    "np.concatenate([np.random.rand(1000), np.random.rand(2000)])[:-1].shape\n",
    "\n",
    "240 - 160 - 160 - 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400.0"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rest_points = (1024 - (0.015 * 16000)) % (0.01 * 16000)\n",
    "buf_sig_len = (0.015 * 16000) + rest_points\n",
    "buf_sig_len\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(347, 40)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sig, sr = sf.read(\"/mingback/wuhw/data/hey_snips_research_6k_en_train_eval_clean_ter/audio_files/662a9628-9494-4722-bf1f-d70ad45e508b.wav\")\n",
    "psf.logfbank(sig, sr, nfilt=40).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "rnn = nn.LSTM(40, 64, 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
